{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5UapjMBUw2yFYSPaYeAVQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huni1i1/Running-Posture-Correction-AI/blob/main/RunningPosetureCorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "pbv-E5_S7dfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmYn0nR9Rwf",
        "outputId": "6d043adf-8650-4fd0-fbc9-44ba6856fd58"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 21 11:40:38 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0              27W /  70W |    373MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gS_REGF7Z1t",
        "outputId": "1ab61015-99fa-4ba9-bf9d-01250c09190e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-257sdkmn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-257sdkmn\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 754469e176b224d17460612bdaa2cb8112b04cd9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6355053 sha256=e9495caf8cb7f1872ed58c51599b6938f2bad01ba9469c9588447a1e1c8264fe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pqd1a5a0/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=af4b6b46058cf1e699aa1c648b417d1bbf6d3e7e3b2f9d279fd97c7bd8e37da3\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=ba491c467a2ac23abc32ead3844f3eea9042c91d0a49b864d05734935a15cde9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# Install Detectron2\n",
        "!pip3 install -q torch\n",
        "!pip3 install -q torchvision\n",
        "!pip3 install pyyaml\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the version\n",
        "import torch, detectron2, os\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wArwVoCm7jNV",
        "outputId": "beca4b67-a4d6-4222-893a-655ee1b2a141"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "torch:  2.5 ; cuda:  cu121\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone VideoPose3D\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/facebookresearch/VideoPose3D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT8lTN-m9u9x",
        "outputId": "2d467ee4-926e-4784-e234-0695ef37d60a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoPose3D'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121 (from 1)\u001b[K\n",
            "Receiving objects: 100% (121/121), 9.53 MiB | 19.67 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change infer_video_d2.py and run.py\n",
        "import shutil\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/Huni1i1/RPC_requirements\n",
        "shutil.move('/content/RPC_requirements/infer_video_d2.py', '/content/VideoPose3D/inference/infer_video_d2.py')\n",
        "shutil.move('/content/RPC_requirements/run.py', '/content/VideoPose3D/run.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "raJ_bMfU9wYc",
        "outputId": "549efe18-c573-49d4-d896-828dbf8d813a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RPC_requirements'...\n",
            "remote: Enumerating objects: 117, done.\u001b[K\n",
            "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
            "remote: Compressing objects: 100% (108/108), done.\u001b[K\n",
            "remote: Total 117 (delta 19), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (117/117), 1.11 MiB | 5.50 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/VideoPose3D/run.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained model\n",
        "os.makedirs('/content/VideoPose3D/checkpoint', exist_ok = True)\n",
        "!wget https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin -P /content/VideoPose3D/checkpoint"
      ],
      "metadata": {
        "id": "0dI2inHl-En0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a4c217-3804-46d2-8bc1-3c14b3df35d9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-21 11:50:06--  https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.70, 13.227.219.33, 13.227.219.10, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67892577 (65M) [application/octet-stream]\n",
            "Saving to: ‘/content/VideoPose3D/checkpoint/pretrained_h36m_detectron_coco.bin’\n",
            "\n",
            "pretrained_h36m_det 100%[===================>]  64.75M   196MB/s    in 0.3s    \n",
            "\n",
            "2024-11-21 11:50:07 (196 MB/s) - ‘/content/VideoPose3D/checkpoint/pretrained_h36m_detectron_coco.bin’ saved [67892577/67892577]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "qGj_DEv3-H3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyv4Zcd6qJmo",
        "outputId": "e1a064b1-b255-4cf2-da67-d13a6fba0a3c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/videos', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/Det2', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/VP3D_joint', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/VP3D_render', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/angles', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/labels', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/checkpoint', exist_ok = True)"
      ],
      "metadata": {
        "id": "20uBMnhdq_n2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ORIGINAL_VIDEOS = '/content/drive/MyDrive/CapstoneDesign/train/original_videos'\n",
        "\n",
        "VIDEOS = '/content/drive/MyDrive/CapstoneDesign/train/videos'\n",
        "DET2 = '/content/drive/MyDrive/CapstoneDesign/train/Det2'\n",
        "VP3D_JOINT = '/content/drive/MyDrive/CapstoneDesign/train/VP3D_joint'\n",
        "VP3D_RENDER = '/content/drive/MyDrive/CapstoneDesign/train/VP3D_render'\n",
        "ANGLES = '/content/drive/MyDrive/CapstoneDesign/train/angles'\n",
        "LABELS = '/content/drive/MyDrive/CapstoneDesign/train/labels'\n",
        "CHECKPOINT = '/content/drive/MyDrive/CapstoneDesign/train/checkpoint'"
      ],
      "metadata": {
        "id": "on9SWz5MMjzk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Crop videos to square\n",
        "# import os\n",
        "# import glob\n",
        "# import subprocess\n",
        "\n",
        "# def crop_video_to_square(input_folder, output_folder):\n",
        "#     video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "#     for input_video_path in video_files:\n",
        "#         output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "#         print(f\"Cropping video: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "#         command = [\n",
        "#         'ffmpeg', '-i', input_video_path,\n",
        "#         '-vf', 'crop=min(in_w\\,in_h):min(in_w\\,in_h)',\n",
        "#         '-c:a', 'copy',\n",
        "#         output_video_path\n",
        "#         ]\n",
        "\n",
        "#         subprocess.run(command)\n",
        "\n",
        "#     print(f\"All videos have been cropped and saved in {output_folder}.\")\n",
        "\n",
        "# crop_video_to_square(ORIGINAL_VIDEOS, VIDEOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOZQ79IvrHo",
        "outputId": "3a3874db-0787-4568-ffee-5dd0a693ed0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/1_0.mp4 -> /content/data/videos/1_0.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/1_1.mp4 -> /content/data/videos/1_1.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/2_0.mp4 -> /content/data/videos/2_0.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/2_1.mp4 -> /content/data/videos/2_1.mp4\n",
            "All videos have been cropped and saved in 'VIDEOS'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample videos to 50fps\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "def resample_videos_to_50fps(input_folder, output_folder):\n",
        "    video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "    for input_video_path in video_files:\n",
        "        output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "        print(f\"Resample video to 50fps: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\", input_video_path,\n",
        "            \"-filter:v\", \"fps=fps=50\",\n",
        "            \"-c:a\", \"copy\",\n",
        "            output_video_path\n",
        "        ]\n",
        "\n",
        "        subprocess.run(command, check=True)\n",
        "\n",
        "    print(f\"All videos have been resampled and saved in {output_folder}.\")\n",
        "\n",
        "resample_videos_to_50fps(ORIGINAL_VIDEOS, VIDEOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQyHNaQnURo",
        "outputId": "b4550b9b-2dc1-496c-a1c5-46c4bd2c9140"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_15.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_15.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_15.mp4\n",
            "All videos have been resampled and saved in /content/drive/MyDrive/CapstoneDesign/train/videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer 2D Keypoints"
      ],
      "metadata": {
        "id": "yxphQ9sppF6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 2D keypoints with Detectron2 and prepare custom dataset\n",
        "def infer_Det2_and_prepare_dataset(video_folder, output_folder):\n",
        "    mp4_files = sorted(glob.glob(os.path.join(video_folder, '*.mp4')))\n",
        "\n",
        "    for mp4_file in mp4_files:\n",
        "        print(f\"Inferring 2D keypoints of {mp4_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/inference')\n",
        "        subprocess.run(['python', 'infer_video_d2.py',\n",
        "                        '--cfg', 'COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml',\n",
        "                        '--output-dir', output_folder,\n",
        "                        '--image-ext', 'mp4',\n",
        "                        mp4_file])\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/data')\n",
        "        subprocess.run(['python', 'prepare_data_2d_custom.py',\n",
        "                        '-i', output_folder,\n",
        "                        '-o', os.path.splitext(os.path.basename(mp4_file))[0]])\n",
        "\n",
        "        for npz_file in glob.glob(os.path.join(output_folder, '*.npz')):\n",
        "          os.remove(npz_file)\n",
        "\n",
        "infer_Det2_and_prepare_dataset(VIDEOS, DET2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzO-Mgw9pCIR",
        "outputId": "79b3b5a5-1727-424b-ba24-dd57c2bc5a7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_15.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_15.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_15.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer 3D Keypoints"
      ],
      "metadata": {
        "id": "vwmZMz3aQO0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/VideoPose3D/data')\n",
        "shutil.copytree('/content/drive/MyDrive/CapstoneDesign/train/data', '/content/VideoPose3D/data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s6JIEa_7Yimn",
        "outputId": "795e4c6b-e2cf-47ce-faa7-fc1e086e7d9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/VideoPose3D/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 3D keypoints with VideoPose3D\n",
        "def infer_VP3D(npz_folder, joint_folder):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name[15:]\n",
        "\n",
        "        print(f\"Inferring 3D keypoints of {npz_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "        subprocess.run(['python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-export', f'{joint_folder}/{video_name}_joint'\n",
        "            ])\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "infer_VP3D(npz_folder, VP3D_JOINT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw6YceWYZJvm",
        "outputId": "116e597a-b61a-4dc9-bea6-48522252e7a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_15.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_15.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_15.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Render 3D keypoints with VideoPose3D\n",
        "def render_VP3D(npz_folder, videos_folder, render_folder):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name.replace('data_2d_custom_', '')\n",
        "\n",
        "        print(f\"Rendering {npz_file} with video name '{video_name}'...\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "\n",
        "        render_command = [\n",
        "            'python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-video', f'{videos_folder}/{video_name}.mp4',\n",
        "            '--viz-output', f'{render_folder}/{video_name}_render.mp4'\n",
        "        ]\n",
        "\n",
        "        subprocess.run(render_command, check=True)\n",
        "\n",
        "        os.remove('/content/VideoPose3D/data/data_2d_custom_'+video_name+'.npz')\n",
        "\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "render_VP3D(npz_folder, VIDEOS, VP3D_RENDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WewHESuOpdoc",
        "outputId": "7cec29f3-8670-4283-ef1b-6af30c0a98a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_02.npz with video name '3_02'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_03.npz with video name '3_03'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_04.npz with video name '3_04'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_05.npz with video name '3_05'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_06.npz with video name '3_06'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_07.npz with video name '3_07'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_08.npz with video name '3_08'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_09.npz with video name '3_09'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_10.npz with video name '3_10'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_11.npz with video name '3_11'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_12.npz with video name '3_12'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_13.npz with video name '3_13'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_14.npz with video name '3_14'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_15.npz with video name '3_15'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset and Labeling"
      ],
      "metadata": {
        "id": "A3OSfdD_TaZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert joints to angles\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class AngleProcessor:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def calcAngle(self, A, B, C):\n",
        "        try:\n",
        "            BA = [A[0] - B[0], A[1] - B[1], A[2] - B[2]]\n",
        "            BC = [C[0] - B[0], C[1] - B[1], C[2] - B[2]]\n",
        "\n",
        "            dot_product = BA[0] * BC[0] + BA[1] * BC[1] + BA[2] * BC[2]\n",
        "            magnitude_BA = math.sqrt(BA[0] ** 2 + BA[1] ** 2 + BA[2] ** 2)\n",
        "            magnitude_BC = math.sqrt(BC[0] ** 2 + BC[1] ** 2 + BC[2] ** 2)\n",
        "\n",
        "            if magnitude_BA == 0 or magnitude_BC == 0:\n",
        "                return 180\n",
        "\n",
        "            cos_theta = dot_product / (magnitude_BA * magnitude_BC)\n",
        "            cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
        "            angle = math.acos(cos_theta)\n",
        "\n",
        "            return math.degrees(angle)\n",
        "        except Exception as e:\n",
        "            print(\"Error calculating angle:\", e)\n",
        "            return 180\n",
        "\n",
        "    def getAngle(self):\n",
        "        data_angle = [[0] * 15 for _ in range(len(self.data))]\n",
        "\n",
        "        for frame in range(len(self.data)):\n",
        "            joints = self.data[frame]\n",
        "            angles = [\n",
        "                (0, 1, 2), (1, 2, 3), (0, 4, 5), (4, 5, 6), (1, 0, 7),\n",
        "                (4, 0, 7), (0, 7, 8), (7, 8, 9), (8, 9, 10), (10, 9, 11),\n",
        "                (9, 11, 12), (1, 12, 13), (10, 9, 14), (9, 14, 15), (14, 15, 16)\n",
        "            ]\n",
        "\n",
        "            for i, (a, b, c) in enumerate(angles):\n",
        "                data_angle[frame][i] = self.calcAngle(joints[a], joints[b], joints[c])\n",
        "\n",
        "        return np.array(data_angle)\n",
        "\n",
        "def process_files(joints_folder, angles_folder):\n",
        "    npy_files = sorted(glob.glob(os.path.join(joints_folder, '*.npy')))\n",
        "\n",
        "    for file_path in npy_files:\n",
        "        try:\n",
        "            keypoints_data = np.load(file_path)\n",
        "            print(f\"Processing {file_path}...\")\n",
        "\n",
        "            processor = AngleProcessor(keypoints_data)\n",
        "            angles = processor.getAngle()\n",
        "\n",
        "            output_file_name = os.path.basename(file_path).replace('_joint.npy', '_angles.npy')\n",
        "            output_path = os.path.join(angles_folder, output_file_name)\n",
        "            np.save(output_path, angles)\n",
        "\n",
        "            print(f\"Saved angles to {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "process_files(VP3D_JOINT, ANGLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozr0Uhqmhcx6",
        "outputId": "c55c3f5c-e7b9-4109-ddaa-2853723feea3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_00_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_00_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_01_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_01_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_02_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_02_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_11_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_11_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_12_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_12_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_13_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_13_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_14_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_14_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/0_15_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/0_15_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_00_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_00_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_01_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_01_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_02_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_02_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_03_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_03_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_12_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_12_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_13_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_13_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/1_14_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/1_14_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_00_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_00_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_01_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_01_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_02_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_02_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_03_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_03_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_04_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_04_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_05_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_05_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_06_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_06_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_07_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_07_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_08_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_08_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_09_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_09_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_10_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_10_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_11_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_11_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_12_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_12_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_13_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_13_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_14_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_14_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/2_15_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/2_15_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_00_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_00_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_01_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_01_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_02_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_02_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_03_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_03_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_04_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_04_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_05_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_05_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_06_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_06_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_07_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_07_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_08_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_08_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_09_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_09_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_10_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_10_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_11_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_11_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_12_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_12_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_13_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_13_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_14_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_14_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/train/VP3D_joint/3_15_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/train/angles/3_15_angles.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling\n",
        "import numpy as np\n",
        "\n",
        "label_mapping = {\n",
        "    0: \"Correct Posture\",\n",
        "    1: \"Leaning Forward\",\n",
        "    2: \"Leaning Backward\",\n",
        "    3: \"Excessive Movement\"\n",
        "}\n",
        "\n",
        "def generate_labels(angles_folder, labels_folder):\n",
        "    angles_files = sorted(glob.glob(os.path.join(angles_folder, '*.npy')))\n",
        "\n",
        "    for angles_file in angles_files:\n",
        "        base_name = os.path.basename(angles_file)\n",
        "        label = int(base_name.split('_')[0])\n",
        "\n",
        "        angles_data = np.load(angles_file)\n",
        "        num_frames = angles_data.shape[0]\n",
        "\n",
        "        labels = np.full((num_frames,), label, dtype=np.int32)\n",
        "\n",
        "        label_file_name = base_name.replace('_angles.npy', '_labels.npy')\n",
        "        label_file_path = os.path.join(labels_folder, label_file_name)\n",
        "\n",
        "        np.save(label_file_path, labels)\n",
        "\n",
        "        print(f\"Label file saved: {label_file_path}\")\n",
        "\n",
        "generate_labels(ANGLES, LABELS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIgUMmMTZrj",
        "outputId": "de392ad6-9e45-46b9-f066-afcd94084fc4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_00_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_01_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_02_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_11_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_12_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_13_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_14_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/0_15_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_00_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_01_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_02_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_03_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_12_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_13_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/1_14_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_00_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_01_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_02_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_03_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_04_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_05_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_06_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_07_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_08_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_09_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_10_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_11_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_12_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_13_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_14_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/2_15_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_00_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_01_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_02_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_03_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_04_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_05_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_06_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_07_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_08_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_09_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_10_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_11_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_12_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_13_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_14_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/train/labels/3_15_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n"
      ],
      "metadata": {
        "id": "8RXMhJX-NAn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "# Custom collate function for variable-length sequences\n",
        "def collate_fn(batch):\n",
        "    inputs = [item[0] for item in batch]  # List of tensors (sequence_length, input_size)\n",
        "    targets = [item[1] for item in batch]  # List of tensors (sequence_length,)\n",
        "\n",
        "    # Pad sequences to match the longest one in the batch\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True)  # (batch_size, max_sequence_length, input_size)\n",
        "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=-1)  # (batch_size, max_sequence_length)\n",
        "\n",
        "    # Calculate sequence lengths\n",
        "    lengths = torch.tensor([len(seq) for seq in inputs], dtype=torch.long)\n",
        "\n",
        "    return padded_inputs, padded_targets, lengths\n",
        "\n",
        "# Define Dataset\n",
        "class PostureDataset(Dataset):\n",
        "    def __init__(self, angles_files, labels_files):\n",
        "        self.angles_files = angles_files\n",
        "        self.labels_files = labels_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.angles_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        angles = np.load(self.angles_files[idx])  # Shape: (sequence_length, input_size)\n",
        "        labels = np.load(self.labels_files[idx])  # Shape: (sequence_length,)\n",
        "\n",
        "        angles_tensor = torch.tensor(angles, dtype=torch.float32)  # Shape: (sequence_length, input_size)\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.long)  # Shape: (sequence_length,)\n",
        "\n",
        "        return angles_tensor, labels_tensor\n",
        "\n",
        "# Define RNN-based model\n",
        "class PostureClassifierRNN(nn.Module):\n",
        "    def __init__(self, input_size=15, hidden_size=64, num_layers=2, num_classes=4):\n",
        "        super(PostureClassifierRNN, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Pack padded sequences\n",
        "        packed_x = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        # LSTM output\n",
        "        packed_out, _ = self.lstm(packed_x)\n",
        "\n",
        "        # Unpack sequences\n",
        "        lstm_out, _ = pad_packed_sequence(packed_out, batch_first=True)  # (batch_size, max_sequence_length, hidden_size)\n",
        "\n",
        "        # Fully connected layer\n",
        "        output = self.fc(lstm_out)  # (batch_size, max_sequence_length, num_classes)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Training function\n",
        "def train_model(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # 모델을 학습 모드로 설정\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels, lengths in dataloader:\n",
        "            # 데이터를 디바이스로 이동\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward 계산\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs, lengths)\n",
        "\n",
        "            # 손실 계산\n",
        "            outputs = outputs.view(-1, outputs.shape[-1])  # (batch_size * max_sequence_length, num_classes)\n",
        "            labels = labels.view(-1)  # (batch_size * max_sequence_length)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward 계산 및 가중치 업데이트\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Prediction function\n",
        "def predict(model, angle_input, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        lengths = torch.tensor([angle_input.shape[0]], dtype=torch.long)\n",
        "        angle_input = torch.tensor(angle_input, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(angle_input, lengths)\n",
        "        _, predicted = torch.max(output, 2)\n",
        "\n",
        "    return predicted.cpu().numpy().flatten()"
      ],
      "metadata": {
        "id": "4315z-Jms1_I"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_angles_files = sorted(glob.glob(f'{ANGLES}/*.npy'))\n",
        "train_labels_files = sorted(glob.glob(f'{LABELS}/*.npy'))\n",
        "\n",
        "input_size = 15\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_classes = 4\n",
        "batch_size = 16\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "train_dataset = PostureDataset(train_angles_files, train_labels_files)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = PostureClassifierRNN(input_size, hidden_size, num_layers, num_classes)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_model(model, train_dataloader, criterion, optimizer, device, num_epochs)\n",
        "\n",
        "model_save_path = f'{CHECKPOINT}/{num_epochs}epochs.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model training completed and saved at {model_save_path}.\")"
      ],
      "metadata": {
        "id": "Y-_2JqzGClFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2debe9-be83-452d-cab3-f9a99f37ccf5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Training Loss: 1.3558\n",
            "Epoch 2/20, Training Loss: 1.3028\n",
            "Epoch 3/20, Training Loss: 1.2516\n",
            "Epoch 4/20, Training Loss: 1.1902\n",
            "Epoch 5/20, Training Loss: 1.1280\n",
            "Epoch 6/20, Training Loss: 1.0405\n",
            "Epoch 7/20, Training Loss: 0.9557\n",
            "Epoch 8/20, Training Loss: 0.8373\n",
            "Epoch 9/20, Training Loss: 0.7110\n",
            "Epoch 10/20, Training Loss: 0.5878\n",
            "Epoch 11/20, Training Loss: 0.5404\n",
            "Epoch 12/20, Training Loss: 0.4454\n",
            "Epoch 13/20, Training Loss: 0.4998\n",
            "Epoch 14/20, Training Loss: 0.4747\n",
            "Epoch 15/20, Training Loss: 0.5895\n",
            "Epoch 16/20, Training Loss: 0.8083\n",
            "Epoch 17/20, Training Loss: 0.5123\n",
            "Epoch 18/20, Training Loss: 0.3740\n",
            "Epoch 19/20, Training Loss: 0.4638\n",
            "Epoch 20/20, Training Loss: 0.5067\n",
            "Model training completed and saved at /content/drive/MyDrive/CapstoneDesign/train/checkpoint/20epochs.pth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "hyN3hB3RkuAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/videos', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/Det2', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/VP3D_joint', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/angles', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/labels', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/RPC', exist_ok = True)"
      ],
      "metadata": {
        "id": "VvKG0yTkkvot"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_ORIGINAL_VIDEOS = '/content/drive/MyDrive/CapstoneDesign/test/original_videos'\n",
        "\n",
        "TEST_VIDEOS = '/content/drive/MyDrive/CapstoneDesign/test/videos'\n",
        "TEST_DET2 = '/content/drive/MyDrive/CapstoneDesign/test/Det2'\n",
        "TEST_VP3D_JOINT = '/content/drive/MyDrive/CapstoneDesign/test/VP3D_joint'\n",
        "TEST_ANGLES = '/content/drive/MyDrive/CapstoneDesign/test/angles'\n",
        "TEST_LABELS = '/content/drive/MyDrive/CapstoneDesign/test/labels'\n",
        "RPC = '/content/drive/MyDrive/CapstoneDesign/test/RPC'"
      ],
      "metadata": {
        "id": "_fl-pqCvk5JZ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample videos to 50fps\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "def resample_videos_to_50fps(input_folder, output_folder):\n",
        "    video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "    for input_video_path in video_files:\n",
        "        output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "        print(f\"Resample video to 50fps: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\", input_video_path,\n",
        "            \"-filter:v\", \"fps=fps=50\",\n",
        "            \"-c:a\", \"copy\",\n",
        "            output_video_path\n",
        "        ]\n",
        "\n",
        "        subprocess.run(command, check=True)\n",
        "\n",
        "    print(f\"All videos have been resampled and saved in {output_folder}.\")\n",
        "\n",
        "resample_videos_to_50fps(TEST_ORIGINAL_VIDEOS, TEST_VIDEOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLTh_uaAlJwj",
        "outputId": "5b9eafbb-c9fa-4e7f-918f-eccd6daff627"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/test/original_videos/0_0.mp4 -> /content/drive/MyDrive/CapstoneDesign/test/videos/0_0.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/test/original_videos/1_0.mp4 -> /content/drive/MyDrive/CapstoneDesign/test/videos/1_0.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/test/original_videos/2_0.mp4 -> /content/drive/MyDrive/CapstoneDesign/test/videos/2_0.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/test/original_videos/3_0.mp4 -> /content/drive/MyDrive/CapstoneDesign/test/videos/3_0.mp4\n",
            "All videos have been resampled and saved in /content/drive/MyDrive/CapstoneDesign/test/videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 2D keypoints with Detectron2 and prepare custom dataset\n",
        "def infer_Det2_and_prepare_dataset(VIDEOS, DET2):\n",
        "    mp4_files = sorted(glob.glob(os.path.join(VIDEOS, '*.mp4')))\n",
        "\n",
        "    for mp4_file in mp4_files:\n",
        "        print(f\"Inferring 2D keypoints of {mp4_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/inference')\n",
        "        subprocess.run(['python', 'infer_video_d2.py',\n",
        "                        '--cfg', 'COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml',\n",
        "                        '--output-dir', DET2,\n",
        "                        '--image-ext', 'mp4',\n",
        "                        mp4_file])\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/data')\n",
        "        subprocess.run(['python', 'prepare_data_2d_custom.py',\n",
        "                        '-i', DET2,\n",
        "                        '-o', os.path.splitext(os.path.basename(mp4_file))[0]])\n",
        "\n",
        "        for npz_file in glob.glob(os.path.join(DET2, '*.npz')):\n",
        "          os.remove(npz_file)\n",
        "\n",
        "infer_Det2_and_prepare_dataset(TEST_VIDEOS, TEST_DET2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZXNmcETlOHW",
        "outputId": "7bb9e4ee-c28a-417f-f12b-d9e74eed9b6a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/test/videos/0_0.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/test/videos/1_0.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/test/videos/2_0.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/test/videos/3_0.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 3D keypoints with VideoPose3D\n",
        "def infer_VP3D(npz_folder, VP3D_JOINT):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name[15:]\n",
        "\n",
        "        print(f\"Inferring 3D keypoints of {npz_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "        subprocess.run(['python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-export', f'{VP3D_JOINT}/{video_name}_joint'\n",
        "            ])\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "infer_VP3D(npz_folder, TEST_VP3D_JOINT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10hMdykdlTzj",
        "outputId": "3042dc5a-809f-40ce-9784-d9395608d5b7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_0.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_0.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_0.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_0.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert joints to angles\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class AngleProcessor:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def calcAngle(self, A, B, C):\n",
        "        try:\n",
        "            BA = [A[0] - B[0], A[1] - B[1], A[2] - B[2]]\n",
        "            BC = [C[0] - B[0], C[1] - B[1], C[2] - B[2]]\n",
        "\n",
        "            dot_product = BA[0] * BC[0] + BA[1] * BC[1] + BA[2] * BC[2]\n",
        "            magnitude_BA = math.sqrt(BA[0] ** 2 + BA[1] ** 2 + BA[2] ** 2)\n",
        "            magnitude_BC = math.sqrt(BC[0] ** 2 + BC[1] ** 2 + BC[2] ** 2)\n",
        "\n",
        "            if magnitude_BA == 0 or magnitude_BC == 0:\n",
        "                return 180\n",
        "\n",
        "            cos_theta = dot_product / (magnitude_BA * magnitude_BC)\n",
        "            cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
        "            angle = math.acos(cos_theta)\n",
        "\n",
        "            return math.degrees(angle)\n",
        "        except Exception as e:\n",
        "            print(\"Error calculating angle:\", e)\n",
        "            return 180\n",
        "\n",
        "    def getAngle(self):\n",
        "        data_angle = [[0] * 15 for _ in range(len(self.data))]\n",
        "\n",
        "        for frame in range(len(self.data)):\n",
        "            joints = self.data[frame]\n",
        "            angles = [\n",
        "                (0, 1, 2), (1, 2, 3), (0, 4, 5), (4, 5, 6), (1, 0, 7),\n",
        "                (4, 0, 7), (0, 7, 8), (7, 8, 9), (8, 9, 10), (10, 9, 11),\n",
        "                (9, 11, 12), (1, 12, 13), (10, 9, 14), (9, 14, 15), (14, 15, 16)\n",
        "            ]\n",
        "\n",
        "            for i, (a, b, c) in enumerate(angles):\n",
        "                data_angle[frame][i] = self.calcAngle(joints[a], joints[b], joints[c])\n",
        "\n",
        "        return np.array(data_angle)\n",
        "\n",
        "def process_files(joints_folder, angles_folder):\n",
        "    npy_files = sorted(glob.glob(os.path.join(joints_folder, '*.npy')))\n",
        "\n",
        "    for file_path in npy_files:\n",
        "        try:\n",
        "            keypoints_data = np.load(file_path)\n",
        "            print(f\"Processing {file_path}...\")\n",
        "\n",
        "            processor = AngleProcessor(keypoints_data)\n",
        "            angles = processor.getAngle()\n",
        "\n",
        "            output_file_name = os.path.basename(file_path).replace('_joint.npy', '_angles.npy')\n",
        "            output_path = os.path.join(angles_folder, output_file_name)\n",
        "            np.save(output_path, angles)\n",
        "\n",
        "            print(f\"Saved angles to {output_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "process_files(TEST_VP3D_JOINT, TEST_ANGLES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8OQfcfJlcEB",
        "outputId": "08dbec68-e7dc-4c5f-904e-f81fe5514685"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/CapstoneDesign/test/VP3D_joint/0_0_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/test/angles/0_0_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/test/VP3D_joint/1_0_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/test/angles/1_0_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/test/VP3D_joint/2_0_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/test/angles/2_0_angles.npy\n",
            "Processing /content/drive/MyDrive/CapstoneDesign/test/VP3D_joint/3_0_joint.npy...\n",
            "Saved angles to /content/drive/MyDrive/CapstoneDesign/test/angles/3_0_angles.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling\n",
        "import numpy as np\n",
        "\n",
        "label_mapping = {\n",
        "    0: \"Correct Posture\",\n",
        "    1: \"Leaning Forward\",\n",
        "    2: \"Leaning Backward\",\n",
        "    3: \"Excessive Movement\"\n",
        "}\n",
        "\n",
        "def generate_labels(angles_folder, labels_folder):\n",
        "    angles_files = sorted(glob.glob(os.path.join(angles_folder, '*.npy')))\n",
        "\n",
        "    for angles_file in angles_files:\n",
        "        base_name = os.path.basename(angles_file)\n",
        "        label = int(base_name.split('_')[0])\n",
        "\n",
        "        angles_data = np.load(angles_file)\n",
        "        num_frames = angles_data.shape[0]\n",
        "\n",
        "        labels = np.full((num_frames,), label, dtype=np.int32)\n",
        "\n",
        "        label_file_name = base_name.replace('_angles.npy', '_labels.npy')\n",
        "        label_file_path = os.path.join(labels_folder, label_file_name)\n",
        "\n",
        "        np.save(label_file_path, labels)\n",
        "\n",
        "        print(f\"Label file saved: {label_file_path}\")\n",
        "\n",
        "generate_labels(TEST_ANGLES, TEST_LABELS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fzwGLXNlgh-",
        "outputId": "2f086e39-05eb-4d29-c5f8-0c5810c534d3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/test/labels/0_0_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/test/labels/1_0_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/test/labels/2_0_labels.npy\n",
            "Label file saved: /content/drive/MyDrive/CapstoneDesign/test/labels/3_0_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer poseture and render video\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "label_mapping = {\n",
        "    0: \"Correct Posture\",\n",
        "    1: \"Leaning Forward\",\n",
        "    2: \"Leaning Backward\",\n",
        "    3: \"Excessive Movement\"\n",
        "}\n",
        "\n",
        "label_colors = {\n",
        "    0: (0, 255, 0),  # Correct Posture -> Green\n",
        "    1: (0, 0, 255),  # Leaning Forward -> Red\n",
        "    2: (0, 0, 255),  # Leaning Backward -> Red\n",
        "    3: (0, 0, 255)   # Excessive Movement -> Red\n",
        "}\n",
        "\n",
        "def render_video_with_posture(video_path, angles_data, predictions, output_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_idx = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_idx >= len(predictions):\n",
        "            break\n",
        "\n",
        "        label = label_mapping[predictions[frame_idx]]\n",
        "        color = label_colors[predictions[frame_idx]]\n",
        "\n",
        "        cv2.putText(frame, f\"Posture: {label}\", (50, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Rendered video saved at {output_path}\")\n",
        "\n",
        "def process_all_files(angles_folder, videos_folder, output_folder, model_path):\n",
        "    angles_files = sorted(glob.glob(os.path.join(angles_folder, '*.npy')))\n",
        "    video_files = sorted(glob.glob(os.path.join(videos_folder, '*.mp4')))\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = PostureClassifierRNN(input_size=15)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "\n",
        "    for angles_file, video_file in zip(angles_files, video_files):\n",
        "        video_name = os.path.basename(video_file)\n",
        "        epoch_name = os.path.splitext(os.path.basename(model_path))[0]\n",
        "        output_video_path = os.path.join(output_folder, f\"{epoch_name}_{video_name}\")\n",
        "\n",
        "        angles_data = np.load(angles_file)\n",
        "\n",
        "        predictions = predict(model, angles_data, device)\n",
        "\n",
        "        render_video_with_posture(video_file, angles_data, predictions, output_video_path)\n",
        "\n",
        "model_path = '/content/drive/MyDrive/CapstoneDesign/train/checkpoint/100epochs.pth'\n",
        "\n",
        "process_all_files(TEST_ANGLES, TEST_VIDEOS, RPC, model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NshiDIbOllVk",
        "outputId": "b0599419-b751-484c-eb41-f158450aa398"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-65-68e30bafda0f>:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendered video saved at /content/drive/MyDrive/CapstoneDesign/test/RPC/100epochs_0_0.mp4\n",
            "Rendered video saved at /content/drive/MyDrive/CapstoneDesign/test/RPC/100epochs_1_0.mp4\n",
            "Rendered video saved at /content/drive/MyDrive/CapstoneDesign/test/RPC/100epochs_2_0.mp4\n",
            "Rendered video saved at /content/drive/MyDrive/CapstoneDesign/test/RPC/100epochs_3_0.mp4\n"
          ]
        }
      ]
    }
  ]
}
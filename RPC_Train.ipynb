{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPZXjx3P615spoXV4E6uR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huni1i1/Running-Posture-Correction-AI/blob/main/RPC_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "pbv-E5_S7dfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmYn0nR9Rwf",
        "outputId": "e593c48b-1a4d-46d8-8852-cd7753e13b93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gS_REGF7Z1t",
        "outputId": "c950d45d-da8c-4ab5-c10a-9dac1d551e76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-50yddvqg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-50yddvqg\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 754469e176b224d17460612bdaa2cb8112b04cd9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.67.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=6354571 sha256=5ddb5f5a5bca331b8d4c14d91c1af9e30c0fcce06940b3073b63f432e7e1f0bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-httkntii/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=0249d1d3296c0f85f26eb7a79c8a37e2238cfac6d2b913563eafa7a25ad66858\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=25f2c51235b5db9a43286b858abbc10aa147d04abe339543a9407b6924c265b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# Install Detectron2\n",
        "!pip3 install -q torch\n",
        "!pip3 install -q torchvision\n",
        "!pip3 install pyyaml\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the version\n",
        "import torch, detectron2, os\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "wArwVoCm7jNV",
        "outputId": "893aa18d-5445-47ed-9352-a9546cb791a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'detectron2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6b5258e8a435>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Check the version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvcc --version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTORCH_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCUDA_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone VideoPose3D\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/facebookresearch/VideoPose3D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT8lTN-m9u9x",
        "outputId": "0183014c-3eba-466b-d190-e08214519eff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoPose3D'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121 (from 1)\u001b[K\n",
            "Receiving objects: 100% (121/121), 9.53 MiB | 28.78 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change infer_video_d2.py and run.py\n",
        "import shutil\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/Huni1i1/RPC_requirements\n",
        "shutil.move('/content/RPC_requirements/infer_video_d2.py', '/content/VideoPose3D/inference/infer_video_d2.py')\n",
        "shutil.move('/content/RPC_requirements/run.py', '/content/VideoPose3D/run.py')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "raJ_bMfU9wYc",
        "outputId": "48231c8c-c3fd-4e8d-c850-cf32da91f4e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RPC_requirements'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 90 (delta 13), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (90/90), 804.53 KiB | 3.89 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/VideoPose3D/run.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained model\n",
        "os.makedirs('/content/VideoPose3D/checkpoint', exist_ok = True)\n",
        "!wget https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin -P /content/VideoPose3D/checkpoint"
      ],
      "metadata": {
        "id": "0dI2inHl-En0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0249329-540c-457c-ec21-13c1d7e0bf5d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-20 10:49:19--  https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.165.160.106, 3.165.160.70, 3.165.160.120, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.165.160.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67892577 (65M) [application/octet-stream]\n",
            "Saving to: ‘/content/VideoPose3D/checkpoint/pretrained_h36m_detectron_coco.bin’\n",
            "\n",
            "pretrained_h36m_det 100%[===================>]  64.75M   143MB/s    in 0.5s    \n",
            "\n",
            "2024-11-20 10:49:19 (143 MB/s) - ‘/content/VideoPose3D/checkpoint/pretrained_h36m_detectron_coco.bin’ saved [67892577/67892577]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "qGj_DEv3-H3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyv4Zcd6qJmo",
        "outputId": "8a011886-0bce-484f-9367-8a98b9df8ec6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/videos', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/Det2', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/VP3D_joint', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/VP3D_render', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/angles', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/labels', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/train/checkpoint', exist_ok = True)"
      ],
      "metadata": {
        "id": "20uBMnhdq_n2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ORIGINAL_VIDEOS = '/content/drive/MyDrive/CapstoneDesign/train/original_videos'\n",
        "\n",
        "VIDEOS = '/content/drive/MyDrive/CapstoneDesign/train/videos'\n",
        "DET2 = '/content/drive/MyDrive/CapstoneDesign/train/Det2'\n",
        "VP3D_JOINT = '/content/drive/MyDrive/CapstoneDesign/train/VP3D_joint'\n",
        "VP3D_RENDER = '/content/drive/MyDrive/CapstoneDesign/train/VP3D_render'\n",
        "ANGLES = '/content/drive/MyDrive/CapstoneDesign/train/angles'\n",
        "LABELS = '/content/drive/MyDrive/CapstoneDesign/train/labels'\n",
        "CHECKPOINT = '/content/drive/MyDrive/CapstoneDesign/train/checkpoint'"
      ],
      "metadata": {
        "id": "on9SWz5MMjzk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Crop videos to square\n",
        "# import os\n",
        "# import glob\n",
        "# import subprocess\n",
        "\n",
        "# def crop_video_to_square(input_folder, output_folder):\n",
        "#     video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "#     for input_video_path in video_files:\n",
        "#         output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "#         print(f\"Cropping video: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "#         command = [\n",
        "#         'ffmpeg', '-i', input_video_path,\n",
        "#         '-vf', 'crop=min(in_w\\,in_h):min(in_w\\,in_h)',\n",
        "#         '-c:a', 'copy',\n",
        "#         output_video_path\n",
        "#         ]\n",
        "\n",
        "#         subprocess.run(command)\n",
        "\n",
        "#     print(f\"All videos have been cropped and saved in {output_folder}.\")\n",
        "\n",
        "# crop_video_to_square(ORIGINAL_VIDEOS, VIDEOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzOZQ79IvrHo",
        "outputId": "3a3874db-0787-4568-ffee-5dd0a693ed0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/1_0.mp4 -> /content/data/videos/1_0.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/1_1.mp4 -> /content/data/videos/1_1.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/2_0.mp4 -> /content/data/videos/2_0.mp4\n",
            "Cropping video: /content/drive/MyDrive/dataset/original_videos/2_1.mp4 -> /content/data/videos/2_1.mp4\n",
            "All videos have been cropped and saved in 'VIDEOS'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample videos to 50fps\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "def resample_videos_to_50fps(input_folder, output_folder):\n",
        "    video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "    for input_video_path in video_files:\n",
        "        output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "        print(f\"Resample video to 50fps: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\", input_video_path,\n",
        "            \"-filter:v\", \"fps=fps=50\",\n",
        "            \"-c:a\", \"copy\",\n",
        "            output_video_path\n",
        "        ]\n",
        "\n",
        "        subprocess.run(command, check=True)\n",
        "\n",
        "    print(f\"All videos have been resampled and saved in {output_folder}.\")\n",
        "\n",
        "resample_videos_to_50fps(ORIGINAL_VIDEOS, VIDEOS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWQyHNaQnURo",
        "outputId": "b4550b9b-2dc1-496c-a1c5-46c4bd2c9140"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/0_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/0_15.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/1_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/1_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/2_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/2_15.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_00.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_00.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_01.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_01.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_02.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_02.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_03.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_03.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_04.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_04.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_05.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_05.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_06.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_06.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_07.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_07.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_08.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_08.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_09.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_09.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_10.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_10.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_11.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_11.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_12.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_12.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_13.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_13.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_14.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_14.mp4\n",
            "Resample video to 50fps: /content/drive/MyDrive/CapstoneDesign/train/original_videos/3_15.mp4 -> /content/drive/MyDrive/CapstoneDesign/train/videos/3_15.mp4\n",
            "All videos have been resampled and saved in /content/drive/MyDrive/CapstoneDesign/train/videos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer 2D Keypoints"
      ],
      "metadata": {
        "id": "yxphQ9sppF6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 2D keypoints with Detectron2 and prepare custom dataset\n",
        "def infer_Det2_and_prepare_dataset(video_folder, output_folder):\n",
        "    mp4_files = sorted(glob.glob(os.path.join(video_folder, '*.mp4')))\n",
        "\n",
        "    for mp4_file in mp4_files:\n",
        "        print(f\"Inferring 2D keypoints of {mp4_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/inference')\n",
        "        subprocess.run(['python', 'infer_video_d2.py',\n",
        "                        '--cfg', 'COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml',\n",
        "                        '--output-dir', output_folder,\n",
        "                        '--image-ext', 'mp4',\n",
        "                        mp4_file])\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/data')\n",
        "        subprocess.run(['python', 'prepare_data_2d_custom.py',\n",
        "                        '-i', output_folder,\n",
        "                        '-o', os.path.splitext(os.path.basename(mp4_file))[0]])\n",
        "\n",
        "        for npz_file in glob.glob(os.path.join(output_folder, '*.npz')):\n",
        "          os.remove(npz_file)\n",
        "\n",
        "infer_Det2_and_prepare_dataset(VIDEOS, DET2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzO-Mgw9pCIR",
        "outputId": "79b3b5a5-1727-424b-ba24-dd57c2bc5a7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/0_15.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/1_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/2_15.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_00.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_01.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_02.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_03.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_04.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_05.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_06.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_07.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_08.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_09.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_10.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_11.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_12.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_13.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_14.mp4\n",
            "Inferring 2D keypoints of /content/drive/MyDrive/CapstoneDesign/train/videos/3_15.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer 3D Keypoints"
      ],
      "metadata": {
        "id": "vwmZMz3aQO0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('/content/VideoPose3D/data')\n",
        "shutil.copytree('/content/drive/MyDrive/CapstoneDesign/train/data', '/content/VideoPose3D/data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s6JIEa_7Yimn",
        "outputId": "795e4c6b-e2cf-47ce-faa7-fc1e086e7d9f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/VideoPose3D/data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 3D keypoints with VideoPose3D\n",
        "def infer_VP3D(npz_folder, joint_folder):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name[15:]\n",
        "\n",
        "        print(f\"Inferring 3D keypoints of {npz_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "        subprocess.run(['python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-export', f'{joint_folder}/{video_name}_joint'\n",
        "            ])\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "infer_VP3D(npz_folder, VP3D_JOINT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw6YceWYZJvm",
        "outputId": "116e597a-b61a-4dc9-bea6-48522252e7a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_0_15.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_1_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_2_15.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_00.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_01.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_02.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_03.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_04.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_05.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_06.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_07.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_08.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_09.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_10.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_11.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_12.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_13.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_14.npz\n",
            "Inferring 3D keypoints of /content/VideoPose3D/data/data_2d_custom_3_15.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Render 3D keypoints with VideoPose3D\n",
        "def render_VP3D(npz_folder, videos_folder, render_folder):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name.replace('data_2d_custom_', '')\n",
        "\n",
        "        print(f\"Rendering {npz_file} with video name '{video_name}'...\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "\n",
        "        render_command = [\n",
        "            'python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-video', f'{videos_folder}/{video_name}.mp4',\n",
        "            '--viz-output', f'{render_folder}/{video_name}_render.mp4'\n",
        "        ]\n",
        "\n",
        "        subprocess.run(render_command, check=True)\n",
        "\n",
        "        os.remove('/content/VideoPose3D/data/data_2d_custom_'+video_name+'.npz')\n",
        "\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "render_VP3D(npz_folder, VIDEOS, VP3D_RENDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WewHESuOpdoc",
        "outputId": "7cec29f3-8670-4283-ef1b-6af30c0a98a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_02.npz with video name '3_02'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_03.npz with video name '3_03'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_04.npz with video name '3_04'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_05.npz with video name '3_05'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_06.npz with video name '3_06'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_07.npz with video name '3_07'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_08.npz with video name '3_08'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_09.npz with video name '3_09'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_10.npz with video name '3_10'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_11.npz with video name '3_11'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_12.npz with video name '3_12'...\n",
            "Rendering /content/VideoPose3D/data/data_2d_custom_3_13.npz with video name '3_13'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset and Labeling"
      ],
      "metadata": {
        "id": "A3OSfdD_TaZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/RPC_requirements')\n",
        "import angle, dl"
      ],
      "metadata": {
        "id": "BSoq3s0vOkT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get angle dataset\n",
        "def process_files(joints_folder, angles_folder):\n",
        "    npy_files = sorted(glob.glob(os.path.join(joints_folder, '*.npy')))\n",
        "\n",
        "    for file_path in npy_files:\n",
        "        keypoints_data = np.load(file_path)\n",
        "        print(f\"Processing {file_path}...\")\n",
        "\n",
        "        processor = AngleProcessor(keypoints_data)\n",
        "        angles = processor.getAngle()\n",
        "\n",
        "        output_file_name = os.path.basename(file_path).replace('.npy', '_angles.npy')\n",
        "        output_path = os.path.join(angles_folder, output_file_name)\n",
        "        np.save(output_path, angles)\n",
        "\n",
        "        print(f\"Saved angles to {output_path}\")\n",
        "\n",
        "\n",
        "process_files(VP3D_JOINT, ANGLES)"
      ],
      "metadata": {
        "id": "ozr0Uhqmhcx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labeling\n",
        "import numpy as np\n",
        "\n",
        "label_mapping = {\n",
        "    0: \"Correct Posture\",\n",
        "    1: \"Leaning Forward\",\n",
        "    2: \"Leaning Backward\",\n",
        "    3: \"Excessive Movement\"\n",
        "}\n",
        "\n",
        "def generate_labels(angles_folder, labels_folder):\n",
        "    angles_files = sorted(glob.glob(os.path.join(angles_folder, '*.npy')))\n",
        "\n",
        "    for angles_file in angles_files:\n",
        "        base_name = os.path.basename(angles_file)\n",
        "        label = int(base_name.split('_')[0])\n",
        "\n",
        "        angles_data = np.load(angles_file)\n",
        "        num_frames = angles_data.shape[0]\n",
        "\n",
        "        labels = np.full((num_frames,), label, dtype=np.int32)\n",
        "\n",
        "        label_file_name = base_name.replace('.npy', '_labels.npy')\n",
        "        label_file_path = os.path.join(labels_folder, label_file_name)\n",
        "\n",
        "        np.save(label_file_path, labels)\n",
        "\n",
        "        print(f\"Label file saved: {label_file_path}\")\n",
        "\n",
        "generate_labels(ANGLES, LABELS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIgUMmMTZrj",
        "outputId": "78142494-d87f-4d11-97ef-eb8779aab155"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labeling /content/data/VP3D/0_0_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 0\n",
            "Labeling /content/data/VP3D/0_1_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 0\n",
            "Labeling /content/data/VP3D/1_0_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 1\n",
            "Labeling /content/data/VP3D/1_1_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 1\n",
            "Labeling /content/data/VP3D/2_0_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 2\n",
            "Labeling /content/data/VP3D/2_1_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 2\n",
            "Labeling /content/data/VP3D/3_0_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 3\n",
            "Labeling /content/data/VP3D/3_1_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 3\n",
            "Labeling /content/data/VP3D/4_0_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 4\n",
            "Labeling /content/data/VP3D/4_1_joint.npy\n",
            "라벨링할 숫자를 입력하세요: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n"
      ],
      "metadata": {
        "id": "8RXMhJX-NAn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "angles_files = sorted(glob.glob(f'{ANGLES}/*.npy'))\n",
        "labels_files = sorted(glob.glob(f'{LABELS}/*.npy'))\n",
        "\n",
        "input_size = 15\n",
        "batch_size = 4\n",
        "dataset = PostureDataset(angles_files, labels_files)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: (\n",
        "    torch.cat([item[0] for item in x], dim=0),\n",
        "    torch.cat([item[1] for item in x], dim=0)\n",
        "))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = PostureClassifierFCNN(input_size=input_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model, dataloader, criterion, optimizer, device, num_epochs=20)\n",
        "\n",
        "model_save_path = CHECKPOINT + '/model.pth'\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model training completed and saved at {model_save_path}.\")"
      ],
      "metadata": {
        "id": "Y-_2JqzGClFS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4eT4FdJ+EytYh/eAsu33N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huni1i1/Running-Posture-Correction-AI/blob/main/VideoPose3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Posture Correction AI"
      ],
      "metadata": {
        "id": "nauOVKKHTjX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Setup"
      ],
      "metadata": {
        "id": "rO3Evh4gTrvS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk_Pk-XrTogM",
        "outputId": "513210df-26dd-4865-e145-a3334b4aebb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/detectron2\n",
        "%cd /content/detectron2\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git"
      ],
      "metadata": {
        "id": "ui79DxGjTvvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone VideoPose3D\n",
        "!git clone https://github.com/facebookresearch/VideoPose3D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRezdT2WUIDO",
        "outputId": "cf937257-835c-406d-ad4e-d7046d3a5030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoPose3D'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121 (from 1)\u001b[K\n",
            "Receiving objects: 100% (121/121), 9.53 MiB | 19.02 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained model(Human3.6M)\n",
        "!mkdir checkpoint\n",
        "%cd checkpoint\n",
        "!wget https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_cpn.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g748WCEsUlwe",
        "outputId": "9486555e-8343-45bf-880f-2635016048a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/checkpoint\n",
            "--2024-10-05 06:32:09--  https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_cpn.bin\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.33.183.33, 13.33.183.115, 13.33.183.29, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.33.183.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67889963 (65M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_h36m_cpn.bin’\n",
            "\n",
            "pretrained_h36m_cpn 100%[===================>]  64.74M  19.4MB/s    in 4.1s    \n",
            "\n",
            "2024-10-05 06:32:14 (15.7 MB/s) - ‘pretrained_h36m_cpn.bin’ saved [67889963/67889963]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "YWqd9HquXeOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup test\n",
        "TEST_WEIGHTS = \"/content/checkpoint/pretrained_h36m_cpn.bin\"\n",
        "PATH_TEST    = \"/content/drive/MyDrive/running_dataset\""
      ],
      "metadata": {
        "id": "OIdWxGrQXmp3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test(Human3.6M)\n",
        "%cd /content/VideoPose3D\n",
        "!python run.py -arc 3,3,3,3,3 -c checkpoint --evaluate TEST_WEIGHTS --dataset PATH_TEST"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwf7rDMhUrcE",
        "outputId": "edf61935-2e5c-4400-ae3c-662aabc56191"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VideoPose3D\n",
            "Namespace(dataset='PATH_TEST', keypoints='cpn_ft_h36m_dbb', subjects_train='S1,S5,S6,S7,S8', subjects_test='S9,S11', subjects_unlabeled='', actions='*', checkpoint='checkpoint', checkpoint_frequency=10, resume='', evaluate='TEST_WEIGHTS', render=False, by_subject=False, export_training_curves=False, stride=1, epochs=60, batch_size=1024, dropout=0.25, learning_rate=0.001, lr_decay=0.95, data_augmentation=True, test_time_augmentation=True, architecture='3,3,3,3,3', causal=False, channels=1024, subset=1, downsample=1, warmup=1, no_eval=False, dense=False, disable_optimizations=False, linear_projection=False, bone_length_term=True, no_proj=False, viz_subject=None, viz_action=None, viz_camera=0, viz_video=None, viz_skip=0, viz_output=None, viz_export=None, viz_bitrate=3000, viz_no_ground_truth=False, viz_limit=-1, viz_downsample=1, viz_size=5)\n",
            "Loading dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/VideoPose3D/run.py\", line 49, in <module>\n",
            "    raise KeyError('Invalid dataset')\n",
            "KeyError: 'Invalid dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization(MP4)\n",
        "!python run.py -k cpn_ft_h36m_dbb -arc 3,3,3,3,3 -c checkpoint --evaluate pretrained_h36m_cpn.bin --render --viz-subject S11 --viz-action Walking --viz-camera 0 --viz-video \"/path/to/videos/S11/Videos/Walking.54138969.mp4\" --viz-output output.gif --viz-size 3 --viz-downsample 2 --viz-limit 60"
      ],
      "metadata": {
        "id": "E2mVoLBsU0NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization(MP4)\n",
        "%cd /content/VideoPose3D\n",
        "!python run.py -arc 3,3,3,3,3 -c checkpoint --evaluate TEST_WEIGHTS --viz-subject S11 --viz-action Walking --viz-camera 0 --viz-video PATH_TEST+\"video1.mp4\" --viz-output output.mp4 --viz-size 5 --viz-downsample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izUGbWvkVVLq",
        "outputId": "3a9d892d-0f93-4f74-fe9c-807b672e9377"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VideoPose3D\n",
            "Namespace(dataset='h36m', keypoints='cpn_ft_h36m_dbb', subjects_train='S1,S5,S6,S7,S8', subjects_test='S9,S11', subjects_unlabeled='', actions='*', checkpoint='checkpoint', checkpoint_frequency=10, resume='', evaluate='TEST_WEIGHTS', render=False, by_subject=False, export_training_curves=False, stride=1, epochs=60, batch_size=1024, dropout=0.25, learning_rate=0.001, lr_decay=0.95, data_augmentation=True, test_time_augmentation=True, architecture='3,3,3,3,3', causal=False, channels=1024, subset=1, downsample=1, warmup=1, no_eval=False, dense=False, disable_optimizations=False, linear_projection=False, bone_length_term=True, no_proj=False, viz_subject='S11', viz_action='Walking', viz_camera=0, viz_video='PATH_TEST+video1.mp4', viz_skip=0, viz_output='output.mp4', viz_export=None, viz_bitrate=3000, viz_no_ground_truth=False, viz_limit=-1, viz_downsample=1, viz_size=5)\n",
            "Loading dataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/VideoPose3D/run.py\", line 41, in <module>\n",
            "    dataset = Human36mDataset(dataset_path)\n",
            "  File \"/content/VideoPose3D/common/h36m_dataset.py\", line 234, in __init__\n",
            "    data = np.load(path, allow_pickle=True)['positions_3d'].item()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\", line 427, in load\n",
            "    fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'data/data_3d_h36m.npz'\n"
          ]
        }
      ]
    }
  ]
}
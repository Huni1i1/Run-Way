{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNYK0Fx22i2BurmPTKORxKe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huni1i1/Running-Posture-Correction-AI/blob/main/RPC_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "8_E52X9vpbt9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1esBguTYpR6x"
      },
      "outputs": [],
      "source": [
        "# Check the gpu\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2\n",
        "!pip3 install -q torch\n",
        "!pip3 install -q torchvision\n",
        "!pip3 install pyyaml\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "id": "hCeZty4Jpfd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone VideoPose3D\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/facebookresearch/VideoPose3D"
      ],
      "metadata": {
        "id": "kCXWvEf2piEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change infer_video_d2.py and run.py\n",
        "import shutil\n",
        "\n",
        "os.chdir('/content')\n",
        "!git clone https://github.com/Huni1i1/RPC_requirements\n",
        "shutil.move('/content/RPC_requirements/infer_video_d2.py', '/content/VideoPose3D/inference/infer_video_d2.py')\n",
        "shutil.move('/content/RPC_requirements/run.py', '/content/VideoPose3D/run.py')"
      ],
      "metadata": {
        "id": "ErQJ_ihOpkTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pre-trained model\n",
        "os.makedirs('/content/VideoPose3D/checkpoint', exist_ok = True)\n",
        "!wget https://dl.fbaipublicfiles.com/video-pose-3d/pretrained_h36m_detectron_coco.bin -P /content/VideoPose3D/checkpoint"
      ],
      "metadata": {
        "id": "-aRllJeupqEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8Qb1sM06PRko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/videos', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/Det2', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/VP3D_joint', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/angles', exist_ok = True)\n",
        "os.makedirs('/content/drive/MyDrive/CapstoneDesign/test/RPC', exist_ok = True)"
      ],
      "metadata": {
        "id": "O2dhWEyfPSXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ORIGINAL_VIDEOS = '/content/drive/MyDrive/CapstoneDesign/test/original_videos'\n",
        "\n",
        "VIDEOS = '/content/drive/MyDrive/CapstoneDesign/test/videos'\n",
        "DET2 = '/content/drive/MyDrive/CapstoneDesign/test/Det2'\n",
        "VP3D_JOINT = '/content/drive/MyDrive/CapstoneDesign/test/VP3D_joint'\n",
        "ANGLES = '/content/drive/MyDrive/CapstoneDesign/test/angles'\n",
        "RPC = '/content/drive/MyDrive/CapstoneDesign/test/RPC'"
      ],
      "metadata": {
        "id": "MjvpKpfbPaUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer Pose"
      ],
      "metadata": {
        "id": "N-cBnRADpwtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample videos to 50fps\n",
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "def resample_videos_to_50fps(input_folder, output_folder):\n",
        "    video_files = sorted(glob.glob(os.path.join(input_folder, '*.mp4')))\n",
        "\n",
        "    for input_video_path in video_files:\n",
        "        output_video_path = os.path.join(output_folder, os.path.basename(input_video_path))\n",
        "\n",
        "        print(f\"Resample video to 50fps: {input_video_path} -> {output_video_path}\")\n",
        "\n",
        "        command = [\n",
        "            \"ffmpeg\",\n",
        "            \"-i\", input_video_path,\n",
        "            \"-filter:v\", \"fps=fps=50\",\n",
        "            \"-c:a\", \"copy\",\n",
        "            output_video_path\n",
        "        ]\n",
        "\n",
        "        subprocess.run(command, check=True)\n",
        "\n",
        "    print(f\"All videos have been resampled and saved in {output_folder}.\")\n",
        "\n",
        "resample_videos_to_50fps(ORIGINAL_VIDEOS, VIDEOS)"
      ],
      "metadata": {
        "id": "lAplaPQRpyTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 2D keypoints with Detectron2 and prepare custom dataset\n",
        "def infer_Det2_and_prepare_dataset(VIDEOS, DET2):\n",
        "    mp4_files = sorted(glob.glob(os.path.join(VIDEOS, '*.mp4')))\n",
        "\n",
        "    for mp4_file in mp4_files:\n",
        "        print(f\"Inferring 2D keypoints of {mp4_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/inference')\n",
        "        subprocess.run(['python', 'infer_video_d2.py',\n",
        "                        '--cfg', 'COCO-Keypoints/keypoint_rcnn_R_101_FPN_3x.yaml',\n",
        "                        '--output-dir', DET2,\n",
        "                        '--image-ext', 'mp4',\n",
        "                        mp4_file])\n",
        "\n",
        "        os.chdir('/content/VideoPose3D/data')\n",
        "        subprocess.run(['python', 'prepare_data_2d_custom.py',\n",
        "                        '-i', DET2,\n",
        "                        '-o', os.path.splitext(os.path.basename(mp4_file))[0]])\n",
        "\n",
        "        for npz_file in glob.glob(os.path.join(DET2, '*.npz')):\n",
        "          os.remove(npz_file)\n",
        "\n",
        "infer_Det2_and_prepare_dataset(VIDEOS, DET2)"
      ],
      "metadata": {
        "id": "crkTZdKWPllO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer 3D keypoints with VideoPose3D\n",
        "def infer_VP3D(npz_folder, VP3D_JOINT):\n",
        "    npz_files = sorted(glob.glob(os.path.join(npz_folder, '*.npz')))\n",
        "\n",
        "    for npz_file in npz_files:\n",
        "        video_name = os.path.splitext(os.path.basename(npz_file))[0]\n",
        "        video_name = video_name[15:]\n",
        "\n",
        "        print(f\"Inferring 3D keypoints of {npz_file}\")\n",
        "\n",
        "        os.chdir('/content/VideoPose3D')\n",
        "        subprocess.run(['python', 'run.py',\n",
        "            '-d', 'custom',\n",
        "            '-k', f'{video_name}',\n",
        "            '-arc', '3,3,3,3,3',\n",
        "            '-c', 'checkpoint',\n",
        "            '--evaluate', 'pretrained_h36m_detectron_coco.bin',\n",
        "            '--render',\n",
        "            '--viz-subject', f'{video_name}.mp4',\n",
        "            '--viz-action', 'custom',\n",
        "            '--viz-camera', '0',\n",
        "            '--viz-size', '10',\n",
        "            '--viz-export', f'{VP3D_JOINT}/{video_name}_joint'\n",
        "            ])\n",
        "\n",
        "npz_folder = '/content/VideoPose3D/data'\n",
        "\n",
        "infer_VP3D(npz_folder, VP3D_JOINT)"
      ],
      "metadata": {
        "id": "YXWUeCYgPpnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/RPC_requirements')\n",
        "import angle, dl"
      ],
      "metadata": {
        "id": "ZTWoCWvfPwPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get angle dataset\n",
        "def process_files(VP3D_JOINT, ANGLES):\n",
        "    npy_files = sorted(glob.glob(os.path.join(VP3D_JOINT, '*.npy')))\n",
        "\n",
        "    for file_path in npy_files:\n",
        "        keypoints_data = np.load(file_path)\n",
        "        print(f\"Processing {file_path}...\")\n",
        "\n",
        "        processor = AngleProcessor(keypoints_data)\n",
        "        angles = processor.getAngle()\n",
        "\n",
        "        output_file_name = os.path.basename(file_path).replace('.npy', '_angles.npy')\n",
        "        output_path = os.path.join(ANGLES, output_file_name)\n",
        "        np.save(output_path, angles)\n",
        "\n",
        "        print(f\"Saved angles to {output_path}\")\n",
        "\n",
        "\n",
        "process_files(VP3D_JOINT, ANGLES)"
      ],
      "metadata": {
        "id": "jfLTA5VZP8uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer poseture and render video\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "label_mapping = {\n",
        "    0: \"Correct Posture\",\n",
        "    1: \"Leaning Forward\",\n",
        "    2: \"Leaning Backward\",\n",
        "    3: \"Excessive Movement\"\n",
        "}\n",
        "\n",
        "def estimate_posture(model, angles_data, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    with torch.no_grad():\n",
        "        angle_tensor = torch.tensor(angles_data, dtype=torch.float32).to(device)\n",
        "        outputs = model(angle_tensor)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "    return predictions.cpu().numpy()\n",
        "\n",
        "def render_video_with_posture(video_path, angles_data, predictions, output_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_idx = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret or frame_idx >= len(predictions):\n",
        "            break\n",
        "\n",
        "        label = label_mapping[predictions[frame_idx]]\n",
        "\n",
        "        cv2.putText(frame, f\"Posture: {label}\", (50, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        out.write(frame)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(f\"Rendered video saved at {output_path}\")\n",
        "\n",
        "def process_all_files(angles_folder, videos_folder, output_folder, model_path):\n",
        "    angles_files = sorted(glob.glob(os.path.join(angles_folder, '*.npy')))\n",
        "    video_files = sorted(glob.glob(os.path.join(videos_folder, '*.mp4')))\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = PostureClassifierFCNN(input_size=15)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.to(device)\n",
        "\n",
        "    for angles_file, video_file in zip(angles_files, video_files):\n",
        "        video_name = os.path.basename(video_file)\n",
        "        output_video_path = os.path.join(output_folder, f\"output_{video_name}\")\n",
        "\n",
        "        angles_data = np.load(angles_file)\n",
        "\n",
        "        predictions = estimate_posture(model, angles_data, device)\n",
        "\n",
        "        render_video_with_posture(video_file, angles_data, predictions, output_video_path)\n",
        "\n",
        "model_path = '/content/RPC_requirements/model.pth'\n",
        "\n",
        "process_all_files(ANGLES, VIDEOS, RPC, model_path)"
      ],
      "metadata": {
        "id": "EHov2xVWRPbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}